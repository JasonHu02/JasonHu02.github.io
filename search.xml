<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LEARNING ROBUST REPRESENTATIONS VIA MULTIVIEW INFORMATION BOTTLENEC-ICLR2020论文解读</title>
      <link href="/2020/01/22/information-bottleneck-paper/"/>
      <url>/2020/01/22/information-bottleneck-paper/</url>
      
        <content type="html"><![CDATA[<p>本文是对于信息瓶颈方法的原始公式应用于在学习时可以使用任务特定标签的监督设置中。提出了通过利用muilt-view的方式 (提供一种实体的两类视图)，可以将方法扩展到无监督的设置。本文通过理论分析得到了多视图的定义。还通过利用标准数据增强技术将理论扩展到单视图，比传统的无监督学习的方法相比，有更好的泛化能力。并在数据集Sketchy和MIR-flickr上进行了实验。</p><p><img src="image/image-20200217022428246.png" alt="image-20200217022428246"></p><p>表示了x和z之间的互信息分成三部份，<strong>第一部分表示为x和z之间的互信息在没有预测为y的情况下</strong>；第二部分<strong>x，y之间的互信息，是一个常数，该常数由原始观测值标签的信息来决定</strong>；减去<strong>第三部分，表示x编码为z丢失的和y有关的互信息</strong>。第二部分和第三部分的区别就是考虑了z情况下的x，y互信息，包含于没有考虑x，y情况下的，所以减去。</p><h4 id="理论"><a href="#理论" class="headerlink" title="理论:"></a>理论:</h4><p>其中涉及到了几个定理和推论，文中均给出了详尽的证明，涉及到大量的信息论和概率的知识，必须借助维基百科()加上自己的手推才能完全理解本文的思路。在此直接列出所有结论。</p><p>定义1，充分性：</p><img src="image/image-20200217143840828.png" alt="image-20200217143840828" style="zoom: 50%;"><p>z对y充分定义为，I(x;y|z)在z条件下的y对x的互信息为0. 由该定义可以推出如下结论:<br>$$<br>I(\mathbf{x} ; \mathbf{y} | \mathbf{z})=0 \Longleftrightarrow I(\mathbf{x} ; \mathbf{y})=I(\mathbf{y} ; \mathbf{z})<br>$$<br>命题2.1：</p><p><img src="image/image-20200217150059055.png" alt="image-20200217150059055"></p><p>定义2，冗余性</p><p><img src="image/image-20200217150236253.png" alt="image-20200217150236253"></p><p>推论1：</p><p><img src="image/image-20200217150331149.png" alt="image-20200217150331149"></p><p>附录部分给出了非常详尽的证明，对任何理解上不到位的地方都可以去看数学推导。</p><h4 id="Related-Work："><a href="#Related-Work：" class="headerlink" title="Related Work："></a>Related Work：</h4><img src="image/image-20200217142805245.png" alt="image-20200217142805245" style="zoom: 50%;"><p>为了比较和其他模型的区别，文中这个图对作者使用的情况进行了详细的解释说明。infomax最大化互信息，来实现无监督学习。理想情况下，良好的表示形式将最大程度地提供有关标签的信息，同时保留来自观察结果的最少信息。也就是图中平行四边形左上方的顶点。从图中可以看到MIB模型是最接近最优解的，本文是第一篇明确指出在多视角无监督学习中丢弃冗余信息的一篇文章。</p><h4 id="实施方法"><a href="#实施方法" class="headerlink" title="实施方法:"></a>实施方法:</h4><p>论文的核心思想在这个图上：</p><img src="image/image-20200217024601501.png" alt="image-20200217024601501" style="zoom: 33%;"><p>在v1和v2两个视图上，分别得到编码得到z1和z2，通过比较两者的分布之间的平均KL散度，以及z1和z2之间的互信息来更新loss。</p><p>它的loss为全文核心：</p><p><img src="image/image-20200217024749741.png" alt="image-20200217024749741"></p><p>散度减去互信息，其表达了用冗余信息减去预测y充分性下的z1和z2的互信息，我们使得在z1|v1和z2|v2下的的KL散度最大化，即v1，v2呈现不同的视角使其给的信息更加无关，而最大化z1和z2之间的互信息，使得z1和z2的信息更加相关。这样的目的都是消除两个变量之间的相关性，也就是信息瓶颈的意思，让最有用的信息通过去，留下对预测没用的多余信息。本文的意图就是想方设法的使得两个不同分布的数据集关联度尽可能小，简单来讲就是让互信息尽可能小。</p><p>最后作者将MIB方法在Sketchy和Flickr数据集上与先前的多视图算法做比较。Sketchy数据集包含来自125个类别的12,500张图像和75,471张手绘草图，是两种信息量上差别很大的图。MIR-Flicker则是通过图像和文字结合，提供两种视角。最后的效果如图所示：分别在Sketchy和Flickr上的效果如下：</p><p>可以看到mv-infomax的实力也非常不错，所以文章主要就是和它在做对比。</p><img src="image/image-20200217030932182.png" alt="image-20200217030932182" style="zoom:33%;"><img src="image/image-20200217025835301.png" alt="image-20200217025835301" style="zoom:33%;"><p>我特地去view了代码，发现代码实现的方法非常简单，说明该方法从某一些理论性的角度解决了模型鲁棒性的问题，训练起来速度很快，有一定的参考价值。且论文作者丝毫不避讳地把实验中所有数据全部公开在论文附录里，看来是对论文地实验效果非常有信心，有足够地把握给读者看。总之，可以借鉴地点非常多。之后工作可以围绕他的思路做一些扩展了。</p><p>核心代码在这里：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> v_1<span class="token punctuation">,</span> v_2<span class="token punctuation">,</span> _ <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>        <span class="token keyword">if</span> cuda<span class="token punctuation">:</span>            v_1 <span class="token operator">=</span> v_1<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            v_2 <span class="token operator">=</span> v_2<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Encode a batch of data</span>        p_z_1_given_v_1 <span class="token operator">=</span> encoder_v_1<span class="token punctuation">(</span>v_1<span class="token punctuation">)</span>        p_z_2_given_v_2 <span class="token operator">=</span> encoder_v_2<span class="token punctuation">(</span>v_2<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Sample from the posteriors with reparametrization</span>        z_1 <span class="token operator">=</span> p_z_1_given_v_1<span class="token punctuation">.</span>rsample<span class="token punctuation">(</span><span class="token punctuation">)</span>        z_2 <span class="token operator">=</span> p_z_2_given_v_2<span class="token punctuation">.</span>rsample<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Mutual information estimation</span>        mi_gradient<span class="token punctuation">,</span> mi_estimation <span class="token operator">=</span> mi_estimator<span class="token punctuation">(</span>z_1<span class="token punctuation">,</span>z_2<span class="token punctuation">)</span>        mi_gradient <span class="token operator">=</span> mi_gradient<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        mi_estimation <span class="token operator">=</span> mi_estimation<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Symmetrized Kullback-Leibler divergence</span>        kl_1_2 <span class="token operator">=</span> p_z_1_given_v_1<span class="token punctuation">.</span>log_prob<span class="token punctuation">(</span>z_1<span class="token punctuation">)</span> <span class="token operator">-</span> p_z_2_given_v_2<span class="token punctuation">.</span>log_prob<span class="token punctuation">(</span>z_1<span class="token punctuation">)</span>        kl_2_1 <span class="token operator">=</span> p_z_2_given_v_2<span class="token punctuation">.</span>log_prob<span class="token punctuation">(</span>z_2<span class="token punctuation">)</span> <span class="token operator">-</span> p_z_1_given_v_1<span class="token punctuation">.</span>log_prob<span class="token punctuation">(</span>z_2<span class="token punctuation">)</span>        skl <span class="token operator">=</span> <span class="token punctuation">(</span>kl_1_2 <span class="token operator">+</span> kl_2_1<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true"># Update the value of beta according to the policy</span>        beta <span class="token operator">=</span> beta_scheduler<span class="token punctuation">(</span>iterations<span class="token punctuation">)</span>        iterations <span class="token operator">+=</span><span class="token number">1</span>        <span class="token comment" spellcheck="true"># Computing the loss function</span>        loss <span class="token operator">=</span> <span class="token operator">-</span> mi_gradient <span class="token operator">+</span> beta <span class="token operator">*</span> skl        <span class="token comment" spellcheck="true"># Logging</span>        mi_over_time<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mi_estimation<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        skl_over_time<span class="token punctuation">.</span>append<span class="token punctuation">(</span>skl<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Backward pass and update</span>        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Plot the loss components every 5 epochs</span>    <span class="token keyword">if</span> epoch <span class="token operator">%</span> plot_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        f<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'$I(z_1;z_2)$'</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'$D_{SKL}(p(z_1|v_1)||p(z_2|v_2))$'</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>mi_over_time<span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>skl_over_time<span class="token punctuation">,</span> <span class="token string">'.r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>        ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span>        f<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">'Epoch: %d'</span><span class="token operator">%</span>epoch<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Compute train and test_accuracy of a logistic regression</span>        train_accuracy<span class="token punctuation">,</span> test_accuracy <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>encoder<span class="token operator">=</span>encoder_v_1<span class="token punctuation">,</span> train_on<span class="token operator">=</span>train_subset<span class="token punctuation">,</span> test_on<span class="token operator">=</span>test_set<span class="token punctuation">,</span> cuda<span class="token operator">=</span>cuda<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Accuracy: %f'</span><span class="token operator">%</span> train_accuracy<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy: %f'</span><span class="token operator">%</span> test_accuracy<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="点评："><a href="#点评：" class="headerlink" title="点评："></a>点评：</h4><p>这是一篇很好的多视角表示学习论文，具有新的见解。learn variable z_1和z_2，它们是一致的，包含视角不变信息，但应尽可能丢弃特定于视角的信息。<br>本文依赖于相互信息估计，并且无需重构。在先前的一些工作中（例如Aaron van den Oord等人2018）中提到，重建损失会引入偏见，对学习的表征产生负面影响。与现有的尝试最大化学习的表示和视图之间的相互信息的多视图表示学习方法相比，本文明确定义了多余的信息，我们应该尝试抛弃这些多余的信息，并弄清楚如何获得足够的学习的表示用于输出。作者还得出了一些现有的（多视图）表示学习方法与他们提出的方法之间的明确联系。</p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information bottleneck </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Meta-learning tutorial</title>
      <link href="/2020/01/12/meta-learning/"/>
      <url>/2020/01/12/meta-learning/</url>
      
        <content type="html"><![CDATA[<p>乘着假期期间，把meta-learning部分的内容全部过一遍。把最近的工作做一些简单的总结，顺便做了一份tutorial方便更多的同学对这个领域quickview。以及提供一部分代码进行实践，深入了解目前元学习领域解决的各种问题。以及非常流行的MAML和Reptile两种模型无关的元学习方法。并尝试从理论上对元学习模型进行解释，learn to learn对于few-shot，zero-shot，one-shot learning都有很好的应用，同时需要掌握的概念有迁移学习和表示学习的概念，了解神经网络学习的主要特征有哪些。本tutorial的参考资料都列到了最后的附录中。</p><h4 id="Meta-learning的两类观点"><a href="#Meta-learning的两类观点" class="headerlink" title="Meta-learning的两类观点"></a>Meta-learning的两类观点</h4><ul><li>一种是Mechanistic view: 可以读取整个数据集并预测新数据点的深度神经网络模型。训练该网络使用一个元数据集，该元数据集本身包含许多数据集，每个数据集用于不同的任务。此观点使实现meta-learning算法更加容易。</li><li>另一种是Probabilistic view：从一组（元训练meta-training）任务中提取先验信息，从而高效地学习新任务学习新任务时, 使用此先验和（小）训练集来推断最有可能的后验参数。此观点使理解元学习算法更加容易。</li></ul><h4 id="元学习的数学定义"><a href="#元学习的数学定义" class="headerlink" title="元学习的数学定义"></a>元学习的数学定义</h4><p>通过学习一类任务，得到一个通用的参数$\theta ^*$,通过固定参数$\theta$ ，在每个训练集的任务上用该task运用该task可以得到$\phi$的训练参数。</p><h5 id="监督学习："><a href="#监督学习：" class="headerlink" title="监督学习："></a>监督学习：</h5><p>目标是:$\arg \max _{\phi} \log p(\phi | D)$ ，其中$\mathcal{D}=\left\{\left(x_{1}, y_{1}\right), \ldots,\left(x_{k}, y_{k}\right)\right\}$ </p><p>其中，xi表示input，比如image，而y表示label。</p><p>$=\arg \max \log p(D | \phi)+\log p(\phi)$</p><p>$=\arg \max \sum_{i} \log p\left(y_{i} | x_{i}, \phi\right)+\log p(\phi)$</p><p>上式可以理解为寻找最大的$\phi$ , 使得学习出来的输出和真实的输出在相似度(极大似然)上最大。其中$\log p(\phi)$ 可以理解为在训练过程中加的正则项，为了防止训练的时候出现过拟合。</p><p>对于监督学习来说，存在的问题是</p><ul><li><p>如果想训练出一个非常强大的模型需要大量的数据，</p></li><li><p>对于一些任务来说label data 非常有限</p></li></ul><h5 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h5><p>实际上，我们可以将数据集分成多个dataset，其中每一个dataset含有不同张图片，我们把这个新的dataset称作是meta-train数据集。</p><p><img src="\image\图片1.png" alt="图片1" style="zoom: 50%;"><img src="meta-learning/image-20200220032921498.png" alt="image-20200220032921498"></p><p>这样就是在每一个Di上都可以学习到需要的参数，最后综合在不同的dataset上学习到的参数作为$\phi$使得其最大。数学上的定义就是：</p><p>$\arg \max _{\phi} \log p\left(\phi | \mathcal{D}, \mathcal{D}_{\text {meta-train }}\right)$</p><p>meta-learning的问题就建立在这样的数据集的基础上，其中$\mathcal{D}=\left\{\left(x_{1}, y_{1}\right), \ldots,\left(x_{k}, y_{k}\right)\right\}$ $\mathcal{D}_{\text {meta-train }}=\left\{\mathcal{D}_{1}, \ldots, \mathcal{D}_{n}\right\}$ ，$\mathcal{D}_{i}=\left\{\left(x_{1}^{i}, y_{1}^{i}\right), \ldots,\left(x_{k}^{i}, y_{k}^{i}\right)\right\}$ .</p><p>因此, 假定$\phi \perp \mathcal{D}_{\text {meta-train }} | \theta$, 表示$ \phi$ 与 $\mathcal{D}_{meta-train}$ 和 $\theta $ 是独立无关的, 可以推导出下面的式子 </p><p>$\log p\left(\phi | \mathcal{D}, \mathcal{D}_{\mathrm{meta}-\mathrm{train}}\right)=\log \int_{\Theta} p(\phi | \mathcal{D}, \theta) p\left(\theta | \mathcal{D}_{\mathrm{meta}-\mathrm{train}}\right) d \theta$  </p><p> $\approx \log p\left(\phi | \mathcal{D}, \theta^{\star}\right)+\log p\left(\theta^{\star} | \mathcal{D}_{\text {meta-train }}\right)$ </p><p>第二行是找到一个平均值$\theta^{\star}$对积分做一个平均得到。其中，第二项中不包含变量$\phi$，为常数项，因此最后问题就变成了：</p><p>$\arg \max _{\phi} \log p\left(\phi | \mathcal{D}, \mathcal{D}_{\text {meta-train }}\right) \approx \arg \max _{\phi} \log p\left(\phi | \mathcal{D}, \theta^{\star}\right)$ </p><p>数学定义完全可以看明白。上式称为是<strong>元学习(meta-learning)需要解决的问题</strong>。要先找到一个$\theta^{*}$ ，再找到最好的$\phi$ 使得能够得到最大的p。</p><h5 id="元学习解决思路及术语介绍："><a href="#元学习解决思路及术语介绍：" class="headerlink" title="元学习解决思路及术语介绍："></a>元学习解决思路及术语介绍：</h5><p>要想使得上式能够得到求解，我们看一下如何进行完整的optimization 过程。优化问题可以分为两部分：</p><ul><li><p>1.第一部分：meta-learning，即$\theta^{\star}=\arg \max _{\theta} \log p\left(\theta | \mathcal{D}_{\text {meta-train }}\right)$ </p></li><li><p>2.第二部分：adaptation. 即 $\phi^{\star}=\arg \max _{\phi} \log p\left(\phi | \mathcal{D}^{\operatorname{tr}}, \theta^{\star}\right)$ </p></li></ul><p>我们将meta-train数据集进行完整的划分：</p><p>$\begin{array}{l}{\mathcal{D}_{\text {meta-train }}=\left\{\left(\mathcal{D}_{1}^{\text {tr }}, \mathcal{D}_{1}^{\text {ts }}\right), \ldots,\left(\mathcal{D}_{n}^{\text {tr }}, \mathcal{D}_{n}^{\text {ts }}\right)\right\}} \\ {D_{i}^{\text {tr }}=\left\{\left(x_{1}^{i}, y_{1}^{i}\right), \ldots,\left(x_{k}^{i}, y_{k}^{i}\right)\right\}} \\ {\mathcal{D}_{i}^{\text {ts }}=\left\{\left(x_{1}^{i}, y_{1}^{i}\right), \ldots,\left(x_{l}^{i}, y_{l}^{i}\right)\right\}}\end{array}$ </p><p>因此，可以将$\phi^{\star}=\arg \max _{\phi} \log p\left(\phi | \mathcal{D}^{\operatorname{tr}}, \theta^{\star}\right)$ 进行训练，得到的参数$\phi$ 即可以表示$\phi^{\star}=f_{\theta^{\star}}\left(\mathcal{D}^{\mathrm{tr}}\right)$ 下的$\theta$ ，通过进行更新参数$\theta$ ，验证在$D^{tr}$得到结果。</p><p>以上可以认为是一个完整的训练过程，其训练$\theta$ 优化数学表达为：</p><p>$\theta^{\star}=\max _{\theta} \sum_{i=1}^{n} \log p\left(\phi_{i} | \mathcal{D}_{\mathcal{i}}^{(\mathrm{ts})}\right)$ </p><p>where $\phi_{i}= f_{\theta}(D_{i}^{tr})$</p><p>要在训练集上最优，使得$\phi=f_{\theta}\left(\mathcal{D}^{\mathrm{tr}}\right)$ 学习到的$\theta$。</p><p>总结来说， 直观上$\phi$ 是在训练任务$D^{tr}$ 中学习得到的通用的经验，我们称它为$f_{\theta}(D_{i}^{tr})$ , 下标表示含有$\theta$ 这个参数，最终目的是要使得在$D_{i}^{ts}$ 上学习到最好的结果——p最大。这样就完成了在少样本测试的情况下给出了最好的分类性能。实现了meta-learning的目的。</p><p>对于数据集中的训练集和测试集，需要重新定义如下图：</p><p><img src="meta-learning/image-20200220032944265.png" alt="image-20200220032944265"></p><p>note：meta-learning的范式也有一些与其非常相关的问题，比如多任务学习(multi-task learning)，或者超参数优化和automl问题。</p><h5 id="元学习常用的几类方法："><a href="#元学习常用的几类方法：" class="headerlink" title="元学习常用的几类方法："></a>元学习常用的几类方法：</h5><p>有四类方法，并不打算过多地展开讲，可以参见我另外一篇博客中使用模型无关的思想做了图像生成的工作，可以说对maml的理解比较深入了。也确实明白这是一个非常不错的工作。这里参考了ICML2019 tutorial的分类，也可以参考 <a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html</a> 的分类，主流方法还是MAML的各种改进。</p><h6 id="1-Black-box-adaptation"><a href="#1-Black-box-adaptation" class="headerlink" title="1.Black-box adaptation"></a>1.Black-box adaptation</h6><p><img src="meta-learning/image-20200220033004659.png" alt="image-20200220033004659"></p><h6 id="2-Opamizaaon-based-inference"><a href="#2-Opamizaaon-based-inference" class="headerlink" title="2.Opamizaaon-based inference"></a>2.Opamizaaon-based inference</h6><p>其中，最经典的莫过于MAML。</p><p>其思路可以直接用下图表示，即让这个loss最小。深入的理解，需要从论文出发。</p><p><img src="meta-learning/image-20200220033024315.png" alt="image-20200220033024315"></p><p><img src="\image\2020-02-16_00-46-53.jpg" alt="2020-02-16_00-46-53" style="zoom: 50%;"><img src="meta-learning/image-20200220033039938.png" alt="image-20200220033039938"></p><h6 id="3-Non-parametric-methods"><a href="#3-Non-parametric-methods" class="headerlink" title="3.Non-parametric methods"></a>3.Non-parametric methods</h6><p><img src="meta-learning/image-20200220033058725.png" alt="image-20200220033058725"></p><h6 id="4-Bayesian-meta-learning"><a href="#4-Bayesian-meta-learning" class="headerlink" title="4.Bayesian meta-learning"></a>4.Bayesian meta-learning</h6><p><img src="meta-learning/image-20200220033114720.png" alt="image-20200220033114720"></p><h5 id="元学习的应用："><a href="#元学习的应用：" class="headerlink" title="元学习的应用："></a>元学习的应用：</h5><p>参考ICML2019tutorial，在语言和图像上都有应用，包括现在比较火的reinforcement learning以及robtic learning。</p><img src="meta-learning/image-20200220033126015.png" alt="image-20200220033126015" style="zoom:50%;"><p><img src="meta-learning/image-20200220033139928.png" alt="image-20200220033139928">：</p><p>上述应用还是在比较传统的领域，实际上，更多的工作开始围绕着强化学习展开，由于强化学习方面的了解的不够深入，今后会继续了解imitation learning相关的工作成果。</p><p>很喜欢这个图：元学习的终极目标，作为本篇文章的结尾！</p><p><img src="meta-learning/image-20200220033150499.png" alt="image-20200220033150499"></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li>ICML2019tutorial上的，Chelsea Finn和Sergey Levine做的lecuture。 <a href="https://sites.google.com/view/icml19metalearning" target="_blank" rel="noopener">https://sites.google.com/view/icml19metalearning</a> (google site)  <a href="https://youtube.videoken.com/embed/DijI4XrhqNo" target="_blank" rel="noopener">https://youtube.videoken.com/embed/DijI4XrhqNo</a> </li><li>hungyi-Lee，台大，<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pptx" target="_blank" rel="noopener">http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pptx</a> ppt, <a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s</a> (video)</li><li>meta-learning比较好的overview: <a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html</a> </li><li>meta-transfer-learning:  <a href="https://yyliu.net/files/meta-transfer-learning-slides.pdf" target="_blank" rel="noopener">https://yyliu.net/files/meta-transfer-learning-slides.pdf</a> (slides) <a href="https://github.com/yaoyao-liu/meta-transfer-learning" target="_blank" rel="noopener">https://github.com/yaoyao-liu/meta-transfer-learning</a> (code)</li><li>few-shot image generation with reptile: <a href="https://github.com/LuEE-C/FIGR" target="_blank" rel="noopener">https://github.com/LuEE-C/FIGR</a> (code) <a href="https://arxiv.org/abs/1901.02199" target="_blank" rel="noopener">https://arxiv.org/abs/1901.02199</a> (paper)</li><li>meta-transfer-learning-gan:  <a href="https://yyliu.net/files/meta-transfer-learning-slides.pdf" target="_blank" rel="noopener">https://yyliu.net/files/meta-transfer-learning-slides.pdf</a> (pdf) <a href="https://arxiv.org/pdf/1812.02391" target="_blank" rel="noopener">https://arxiv.org/pdf/1812.02391</a> (paper)</li></ul>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> meta-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二零一七年终总结</title>
      <link href="/2018/01/22/2017-conclusion/"/>
      <url>/2018/01/22/2017-conclusion/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=407679465&auto=1&height=66"></iframe></div><p>时间过得很快，终于等到放寒假了，虽然这几个月没有课，天天和放假也没啥区别呢。细数一下，还有5个月就要毕业了吧，大一刚入学的场景却依然清楚地记得，转眼间就成了老学长了呢。闲来无事，随便写写，有感而发，无病呻吟而已。</p><h1 id="2017"><a href="#2017" class="headerlink" title="2017"></a>2017</h1><hr><p>回顾我的2017，没做什么事，令我能记得就3件大事吧：</p><ul><li>失恋ing</li><li>ACM退役</li><li>顺利保研</li></ul><p><strong>第一件事</strong>就不想过多回忆了，<strong>2014.12.13 ~ 2017.03.01</strong>，曲终人散。<br><img src="749826.jpg" alt><br>最后引用《我的少女时代》里的一句话吧。</p><blockquote><p>每人都有一颗林真心，遇见是最美好的小幸运，谢谢你出现在我的青春里。</p></blockquote><p><img src="1.jpg" alt><br><strong>第二件事</strong>其实也是黯淡退出吧，大三下开始课程繁忙，也就没怎么训练了，再加上暑假考驾照，于是乎就退役了。回顾三年来，从大一入学时电脑都没怎么碰过的小白，到现在算法也略有所知，也是付出过很大的努力吧，毕竟当年每天刷题，为了一个bug而熬夜到凌晨。最后也算是混了个水水的金牌，奖项不算耀眼。但最重要的是从这段经历中，学到了拼搏、坚持的一种精神，这对以后的研究生涯想必也有很大帮助。<br><img src="2.jpg" alt><br><strong>第三件事</strong>也是意料之中吧，没有什么波折。纠结了很多，虽然<strong>专业第一</strong>，但是最后还是选择保了本校。要问原因，也许是校园情怀，也许是导师人很好，也许是为了方便更早研究，也许就是懒吧。现在尘埃落定，靠人靠天不如靠自己，继续努力吧。<br><img src="3.jpg" alt></p><p>过去的一年，学业未有很大长进，看着同学们整页的4.0绩点，心里倒也没有什么不平衡了。下学期保了研之后选了一门研究生的文本挖掘课，也马马虎虎读了几十篇论文，也算是对自然语言处理和深度学习入了个门，最后的presentation做的还算满意。</p><h1 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h1><hr><p>今年最重要的大事莫过于毕业论文了，因为以后要做的方向是句法分析，所以导师给我的毕业论文安排的就是《基于循环神经网络的成分句法分析》。虽然说是基于ACL2013的一篇论文改编的，但是目前为止，我还没有发现有人做和这个完全一样的。也许最后写的好的话可以直接发paper了。</p><p>但是目前基本的框架还没完全搭建起来吧，代码还不是很熟练，现在只写了一个最基础的动态规划+RNN。最近有如下计划：</p><ul><li>准备试一下动态规划+LSTM。</li><li>然后动态规划扩增一个维度，用来保存左右结点的head结点。</li><li>如果这个写好了，就可以和我github找到的PCFG+CYK代码融合了，准备加上每个结点的POS。</li><li>最后加入预训练词向量应该就基本完成了。</li></ul><p>希望能顺利毕业吧，前一段时间一直对一些实现细节有些困惑，代码还写错了，还以为理论错了。也不知道最后出来的结果会怎么样，希望能不错。</p><p>生活方面，最近半年越来越懒了，极少出门，睡得晚，起的也晚。最近买了把尤克里里，也算是陶冶陶冶情操吧，不至于一直盯着电脑。现在也小有长进，能弹一点点了。</p><p>现在能聊天的人越来越少了，QQ微信放那一天也不一定会有人来找，就算有人也多半是咨询问题的，等一个可以交心的人吧。有时我也想过，我是不是太像中央空调了，对所有人都这么有耐心，到头来却还是一个人，付出那么多最后还是一无所有。<br><img src="4.jpg" alt><br>最后还是祝自己2018年顺利吧，希望毕业顺利，研究生涯小有收获，最后等一个有缘人吧。</p><blockquote><p>我遇见谁，会有怎样的对白。<br>我等的人，她在多远的未来。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
